{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47400a47",
   "metadata": {},
   "source": [
    "### Spacy \n",
    "\n",
    "the workflow of a general nlp project is as follows <br>\n",
    "-> Data Acquisition <br>\n",
    "-> Text extraction and cleanup <br>\n",
    "-> Pre processing -> Sentence Vectorization -> Word Vectorization (Spacy and NLTK) ( stemming and lemmatization ) <br>\n",
    "-> Feature Engineering <br>\n",
    "-> Model Building <br>\n",
    "-> Evaluation <br>\n",
    "-> Deployment <br>\n",
    "-> Monitor and Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0386f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f111e10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "an\n",
      "NLP\n",
      "study\n",
      "note\n",
      ".\n",
      "It\n",
      "will\n",
      "be\n",
      "hosted\n",
      "in\n",
      "github\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\") # used for classifying englsh language there are other prebuilt nlp pipelines you can use please read throug spacy documentation \n",
    "\n",
    "doc = nlp(\"This is an NLP study note. It will be hosted in github\")\n",
    "\n",
    "for token in doc: \n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06acbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\"\n",
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "NY\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\") # used for classifying englsh language there are other prebuilt nlp pipelines you can use please read throug spacy documentation \n",
    "\n",
    "doc = nlp(''' \"Let's go to NY\" ''') # the output shows that instead of converting the sentence into separate words like the split() function we can use this package to help split it into meaning full chunks that are beneficial for the model training \n",
    "\n",
    "for token in doc: \n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14941618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n"
     ]
    }
   ],
   "source": [
    "# slicing \n",
    "\n",
    "doc = nlp(\"This is Dev's notebook\")\n",
    "\n",
    "token0 = doc[0]\n",
    "\n",
    "print(token0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd66a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['List of Students and details \\n',\n",
       " '\\n',\n",
       " 'Student    Email \\n',\n",
       " 'Dev        dev.thiyyadi@gmail.com\\n',\n",
       " 'Hari       hari@gmail.com\\n',\n",
       " 'Saran      saran@gmail.com']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# does email extraction from files much easier than regex \n",
    " \n",
    "with open(\"spacyexample.txt\") as f: \n",
    "     text = f.readlines()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c1e456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'List of Students and details \\n \\n Student    Email \\n Dev        dev.thiyyadi@gmail.com\\n Hari       hari@gmail.com\\n Saran      saran@gmail.com'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(text) # removing separate lines \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4633bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.thiyyadi@gmail.com\n",
      "hari@gmail.com\n",
      "saran@gmail.com\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "email = []\n",
    "for token in doc: \n",
    "    if token.like_email:\n",
    "        email.append(token)\n",
    "\n",
    "for i in email:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Gen",
   "language": "python",
   "name": "ai_gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
